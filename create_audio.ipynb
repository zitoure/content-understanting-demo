{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation -> JSON -> Audio\n",
    "\n",
    "This notebook generates multi-turn conversations using an LLM, saves them as JSON, and generates audio files from those conversations using Azure Text-to-Speech.\n",
    "\n",
    "What this notebook does:\n",
    "\n",
    "- Generates conversation JSON for several topics using configured prompts.\n",
    "- Saves generated conversation JSON into `generated_data_2/`.\n",
    "- Converts conversation JSON into SSML and uses Azure Cognitive Services Text-to-Speech to create WAV audio files.\n",
    "\n",
    "Prerequisites (set these in your environment or a `.env` file):\n",
    "\n",
    "- AZURE_OPENAI_API_KEY\n",
    "- AZURE_OPENAI_API_VERSION (if required)\n",
    "- AZURE_OPENAI_ENDPOINT\n",
    "- AZURE_SPEECH_KEY\n",
    "- AZURE_SPEECH_REGION\n",
    "\n",
    "Quick run (from repo root):\n",
    "\n",
    "1. Ensure environment variables are set (or create a `.env` file).\n",
    "2. In a Python environment with dependencies installed, run the cells top-to-bottom.\n",
    "\n",
    "Helpful installs (run in your terminal if needed):\n",
    "```bash\n",
    "python -m pip install python-dotenv requests openai\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Run cells in order. If any API calls fail, check your keys and quota.\n",
    "- The final cell will create audio files under `./data/en` (or `./data/non_en`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI chat completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# The Azure OpenAI client wrapper (AzureOpenAI) is used to call chat completion endpoints\n",
    "# Ensure the azure/openai client library is installed and configured correctly for your environment.\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env if present\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "deployment = os.getenv('AZURE_OPENAI_DEPLOYMENT', 'gpt-4o-mini')  # Use deployment from env or fallback\n",
    "\n",
    "def get_openai_response(prompt: str) -> str:\n",
    "    \"\"\"Call Azure OpenAI chat completion and return assistant text content.\n",
    "    Args:\n",
    "        prompt (str): The prompt to send as a user message.\n",
    "    Returns:\n",
    "        str: The assistant response content.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        temperature=0.9,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Response shape depends on client; adapt if necessary\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.geriatric_health import CONVERSATION_PROMPT as geriatric_health_prompt\n",
    "from prompts.golf_coaching import CONVERSATION_PROMPT as golf_coaching_prompt\n",
    "from prompts.mental_health import CONVERSATION_PROMPT as mental_health_prompt\n",
    "from prompts.physical_health import CONVERSATION_PROMPT as physical_health_prompt\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_conversation(prompt: str) -> str:\n",
    "    \"\"\"Generate a conversation string from LLM using the provided prompt.\n",
    "    This function wraps the Azure OpenAI call and returns raw string output from the model.\n",
    "    \"\"\"\n",
    "    print(\"Requesting conversation from model...\")\n",
    "    return get_openai_response(prompt)\n",
    "\n",
    "os.makedirs(\"generated_data\", exist_ok=True)  # ensure output folder exists\n",
    "\n",
    "prompts = [\n",
    "    (\"mental_health\", mental_health_prompt),\n",
    "    (\"physical_health\", physical_health_prompt),\n",
    "    (\"geriatric_health\", geriatric_health_prompt),\n",
    "    (\"golf_coaching\", golf_coaching_prompt)\n",
    "]\n",
    "\n",
    "for name, prompt in prompts:\n",
    "    print(f\"Generating conversation for: {name}\")\n",
    "    conversation = generate_conversation(prompt)\n",
    "    # Many models return code fences around JSON; try to strip those safely\n",
    "    if conversation.strip().startswith(\"```\") and \"json\" in conversation.lower():\n",
    "        conversation = conversation.strip().lstrip(\"```json\").rstrip(\"```\").strip()\n",
    "    try:\n",
    "        conv_json = json.loads(conversation)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse JSON response for {name}: {e}. Trying fallback replacements...\")\n",
    "        # fallback: try to fix common issues such as single quotes or newlines\n",
    "        conv_json = json.loads(conversation.replace(\"\\n\", \" \").replace(\"'\", '\"'))\n",
    "    # Save output to file for later audio generation\n",
    "    with open(f\"generated_data/{name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(conv_json, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved generated conversation to generated_data_2/{name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "def load_json_from_file(file_path: str) -> dict:\n",
    "    \"\"\"Loads a JSON object from a file and returns it.\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "    Returns:\n",
    "        dict: Parsed JSON content.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"JSON file not found: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def convert_conv_to_json(conv: str) -> dict:\n",
    "    \"\"\"Convert a model output string that contains JSON into a dict.\n",
    "    Handles code fences and minor formatting errors.\n",
    "    Args:\n",
    "        conv (str): Raw model output string.\n",
    "    Returns:\n",
    "        dict: Parsed JSON object.\n",
    "    \"\"\"\n",
    "    # Remove common code fence wrappers\n",
    "    conv_cleaned = conv.strip()\n",
    "    if conv_cleaned.startswith('```') and 'json' in conv_cleaned[:10].lower():\n",
    "        conv_cleaned = conv_cleaned.split('```', 1)[1].strip()\n",
    "    conv_cleaned = conv_cleaned.strip('`\\n ')\n",
    "    # Try to parse normally, then try safe replacements\n",
    "    try:\n",
    "        return json.loads(conv_cleaned)\n",
    "    except Exception:\n",
    "        # Fallback: replace single quotes and excessive newlines\n",
    "        safe = conv_cleaned.replace(\"\\n\", \" \").replace(\"'\", '\"')\n",
    "        return json.loads(safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "# Concatenate audio files using wave module\n",
    "import wave\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure Text to Speech API details - ensure these are set in your environment\n",
    "subscription_key = os.getenv(\"AZURE_SPEECH_KEY\")\n",
    "region = os.getenv(\"AZURE_SPEECH_REGION\")\n",
    "\n",
    "# Candidate voices used for TTS - change or extend as required\n",
    "en_voices = [\n",
    "    \"en-US-JennyNeural\", \"en-US-GuyNeural\", \"en-US-AriaNeural\", \"en-US-DavisNeural\",\n",
    "    \"en-GB-LibbyNeural\", \"en-GB-RyanNeural\", \"en-AU-NatashaNeural\", \"en-AU-WilliamNeural\",\n",
    "    \"en-ZA-LeahNeural\", \"en-ZA-LukeNeural\",\n",
    "]\n",
    "\n",
    "non_en_voices = [\n",
    "    \"es-ES-ElviraNeural\", \"es-MX-DaliaNeural\", \"zh-CN-XiaoxiaoNeural\", \"hi-IN-SwaraNeural\",\n",
    "    \"pt-BR-FranciscaNeural\", \"de-DE-KatjaNeural\", \"es-ES-AlvaroNeural\", \"es-MX-JorgeNeural\",\n",
    "    \"zh-CN-YunxiNeural\", \"hi-IN-MadhurNeural\", \"pt-BR-AntonioNeural\", \"de-DE-ConradNeural\",\n",
    "]\n",
    "\n",
    "def generate_audio_from_conversation(conv_json: dict, output_name: str, agent1_name: str, agent2_name: str, use_non_en_voices: bool=False) -> None:\n",
    "    \"\"\"Generate audio for a conversation JSON and write concatenated WAV file.\n",
    "    Args:\n",
    "        conv_json (dict): Conversation JSON with `conversation` list of {role: text} entries.\n",
    "        output_name (str): Base output name for produced audio file(s).\n",
    "        agent1_name (str): Name of participant 1 as present in conversation JSON.\n",
    "        agent2_name (str): Name of participant 2 as present in conversation JSON.\n",
    "        use_non_en_voices (bool): Whether to prioritize non-English voices.\n",
    "    \"\"\"\n",
    "\n",
    "    endpoint = f\"https://{region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "    # Select voice pools based on language preference\n",
    "    if use_non_en_voices:\n",
    "        folder = './data/non_en'\n",
    "        voices = non_en_voices + en_voices\n",
    "    else:\n",
    "        folder = './data/en'\n",
    "        voices = en_voices\n",
    "    # Ensure directories exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    os.makedirs('./.temp', exist_ok=True)\n",
    "\n",
    "    agent1 = {\n",
    "        \"name\": agent1_name,\n",
    "        \"voice\": random.choice(voices)\n",
    "    }\n",
    "    agent2 = {\n",
    "        \"name\": agent2_name,\n",
    "        \"voice\": random.choice(list(reversed(voices)))\n",
    "    }\n",
    "    print(f\"Using voices: {agent1['voice']} (for {agent1_name}), {agent2['voice']} (for {agent2_name})\")\n",
    "\n",
    "    # Build SSML for each message with slight variation in speed for naturalness\n",
    "    ssml_parts = []\n",
    "    for line in conv_json.get('conversation', []):\n",
    "        for role, text in line.items():\n",
    "            if role == \"order\":\n",
    "                continue\n",
    "            voice = agent1['voice'] if role == agent1['name'] else agent2['voice']\n",
    "            speed = round(random.uniform(1.1, 1.4), 2)\n",
    "            ssml = f\"\"\"\n",
    "            <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-US'>\n",
    "                <voice name='{voice}'>\n",
    "                    <prosody rate='{speed}'>{text}</prosody>\n",
    "                </voice>\n",
    "            </speak>\n",
    "            \"\"\"\n",
    "            ssml_parts.append(ssml)\n",
    "\n",
    "    # Call Azure TTS for each SSML segment and save to temporary wav files\n",
    "    audio_files = []\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "        'Content-Type': 'application/ssml+xml',\n",
    "        'X-Microsoft-OutputFormat': 'riff-24khz-16bit-mono-pcm'\n",
    "    }\n",
    "\n",
    "    for i, ssml in enumerate(ssml_parts):\n",
    "        response = requests.post(endpoint, headers=headers, data=ssml.encode('utf-8'))\n",
    "        if response.status_code == 200:\n",
    "            temp_audio_path = f'./.temp/part_{i}.wav'\n",
    "            with open(temp_audio_path, 'wb') as audio_file:\n",
    "                audio_file.write(response.content)\n",
    "            audio_files.append(temp_audio_path)\n",
    "        else:\n",
    "            print(f\"Error generating audio for part {i}: {response.status_code} - {response.text}\")\n",
    "\n",
    "    if not audio_files:\n",
    "        print(\"No audio files were generated; aborting concatenation.\")\n",
    "        return\n",
    "\n",
    "    # Create final filename using voices for traceability\n",
    "    file_name = f'{output_name}_{agent1[\"voice\"][:5]}_{agent2[\"voice\"][:5]}'\n",
    "    final_audio_path = f'{folder}/{file_name}.wav'\n",
    "\n",
    "    # Concatenate WAV files into a single file\n",
    "    with wave.open(final_audio_path, 'wb') as final_audio:\n",
    "        with wave.open(audio_files[0], 'rb') as part:\n",
    "            final_audio.setparams(part.getparams())\n",
    "            final_audio.writeframes(part.readframes(part.getnframes()))\n",
    "        for audio_file in audio_files[1:]:\n",
    "            with wave.open(audio_file, 'rb') as part:\n",
    "                final_audio.writeframes(part.readframes(part.getnframes()))\n",
    "\n",
    "    print(f\"Saved final audio to {final_audio_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'clinician', 'voice': 'en-AU-NatashaNeural'} {'name': 'patient', 'voice': 'en-ZA-LeahNeural'}\n"
     ]
    }
   ],
   "source": [
    "conversation_files = [\n",
    "    (\"generated_data/mental_health.json\", \"mental_health\", \"clinician\", \"patient\"),\n",
    "    (\"generated_data/physical_health.json\", \"physical_health\", \"clinician\", \"patient\"),\n",
    "    (\"generated_data/geriatric_health.json\", \"geriatric_health\", \"clinician\", \"patient\"),\n",
    "    (\"generated_data/golf_coaching.json\", \"golf_coaching\", \"coach\", \"athlete\"),\n",
    "]\n",
    "\n",
    "for file_path, output_name, agent1, agent2 in conversation_files:\n",
    "    conv_json = load_json_from_file(file_path)\n",
    "    generate_audio_from_conversation(conv_json, output_name, agent1, agent2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the full notebook\n",
    "\n",
    "> After setting environment variables, run all code cells from top to bottom.\n",
    "\n",
    "> If you only want to generate audio for existing JSON files, run only the `generate_audio_from_conversation` cell and the final loop cell.\n",
    "\n",
    "Common errors and fixes:\n",
    "\n",
    "- API key errors: check `.env` and environment variables are set correctly.\n",
    "- Parsing errors: model returned non-JSON; inspect the raw string (print it) and fix the prompt or parsing logic.\n",
    "- TTS failures: verify `AZURE_SPEECH_KEY` and `AZURE_SPEECH_REGION` and that your subscription supports the requested voice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
